model_tested,gpu,number_concurrent_requests,avg_time_to_first_token,95_percentile_time_to_first_token,end_to_end_latency,95_percentile_end_to_end_latency,avg_output_length,avg_tokens_per_second,percentage_failed_requests,avg_token_count
meta-llama/Llama-3.1-8B-Instruct,1-H100,10,0.66,1.16,4.04,8.55,1367.56,92.13,0.0,306.52
meta-llama/Llama-3.1-8B-Instruct,1-H100,50,0.9,1.18,4.89,10.03,1505.72,81.85,0.0,321.52
meta-llama/Llama-3.1-8B-Instruct,1-H100,100,1.35,1.92,5.83,11.45,1529.71,70.78,0.0,324.08
meta-llama/Llama-3.1-8B-Instruct,1-H100,200,2.22,6.3,7.35,15.14,1514.19,62.74,0.2,326.64
meta-llama/Llama-3.1-8B-Instruct,1-H100,400,7.77,17.11,12.97,24.75,1474.94,60.32,0.1,313.51
meta-llama/Llama-3.1-8B-Instruct,1-H100,500,9.95,22.17,15.46,29.84,1545.49,59.01,0.12,330.26
